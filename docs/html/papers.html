<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>pvx Research Bibliography (Phase Vocoder and Related DSP)</title>
  <link rel="stylesheet" href="style.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
  <header class="site-header">
    <div class="wrap">
      <h1>pvx Research Bibliography (Phase Vocoder and Related DSP)</h1>
      <nav><a href="index.html">Home</a> | <a href="glossary.html">Technical glossary</a> | <a href="math.html">Math</a> | <a href="windows.html">Windows</a> | <a href="citations.html">Citation quality</a></nav>
    </div>
  </header>
  <main class="wrap">
<div class="card">
  <p>
    This bibliography collects foundational and directly related literature that informed
    PVX's phase-vocoder-centric architecture and the broader DSP algorithm roadmap.
  </p>
  <p>
    Total references: <strong>165</strong> across <strong>9</strong> categories.
  </p>
  <p class="small">
    Links point to DOI pages, publisher archives, arXiv, standards documents, project docs,
    or Google Scholar queries where an official landing page can vary by publisher access.
  </p>
</div>

<div class="card"><h2>Categories</h2><ul><li><a href="#phase-vocoder-foundations">Phase Vocoder Foundations (21)</a></li><li><a href="#time-scale-and-pitch-methods">Time-Scale and Pitch Methods (14)</a></li><li><a href="#pitch-detection-and-tracking">Pitch Detection and Tracking (17)</a></li><li><a href="#time-frequency-and-transform-methods">Time-Frequency and Transform Methods (19)</a></li><li><a href="#separation-and-decomposition">Separation and Decomposition (21)</a></li><li><a href="#denoising-dereverberation-and-spatial-audio">Denoising, Dereverberation, and Spatial Audio (33)</a></li><li><a href="#spatial-audio-beamforming-and-ambisonics">Spatial Audio, Beamforming, and Ambisonics (20)</a></li><li><a href="#loudness-dynamics-and-mastering">Loudness, Dynamics, and Mastering (10)</a></li><li><a href="#ml-audio-and-neural-vocoding">ML Audio and Neural Vocoding (10)</a></li></ul></div>
<h2 id="phase-vocoder-foundations">Phase Vocoder Foundations</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2013</td><td>M. Dolson</td><td>History of the Phase Vocoder</td><td>CCRMA Note</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=History+of+the+Phase+Vocoder" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>B. Zavalishin</td><td>The Art of VA Filter Design (sections on phase and spectral processing)</td><td>Book</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=The+Art+of+VA+Filter+Design+%28sections+on+phase+and+spectral+processing%29" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2009</td><td>N. Moreau</td><td>Toolbox for Time-Scale Modification and Pitch-Shifting of Audio Signals</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Toolbox+for+Time-Scale+Modification+and+Pitch-Shifting+of+Audio+Signals" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2003</td><td>A. Röbel</td><td>A New Approach to Transient Processing in the Phase Vocoder</td><td>DAFx</td><td><code>web</code></td><td><a href="https://www.dafx.de/paper-archive/2003/pdfs/dafx81.pdf" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2002</td><td>C. Duxbury; M. Davies; M. Sandler</td><td>Improved Time-Scaling of Musical Audio Using Phase Locking at Transients</td><td>AES Convention</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Improved+Time-Scaling+of+Musical+Audio+Using+Phase+Locking+at+Transients" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2000</td><td>J. Bonada</td><td>Automatic Technique in Frequency Domain for Near-Lossless Time-Scale Modification of Audio</td><td>ICMC</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Automatic+Technique+in+Frequency+Domain+for+Near-Lossless+Time-Scale+Modification+of+Audio" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>S. M. Bernsee</td><td>Pitch Shifting Using the Fourier Transform</td><td>DAFX Workshop Note</td><td><code>web</code></td><td><a href="https://blogs.zynaptiq.com/bernsee/pitch-shifting-using-the-ft/" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>J. Laroche; M. Dolson</td><td>New Phase-Vocoder Techniques for Pitch-Shifting, Harmonizing and Other Exotic Effects</td><td>WASPAA</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/ASPAA.1999.810857" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>J. Laroche; M. Dolson</td><td>Improved Phase Vocoder Time-Scale Modification of Audio</td><td>IEEE Trans. Speech and Audio Processing</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/89.759041" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1998</td><td>S. Disch</td><td>A New Phase Vocoder Technique for Time-Scale Modification of Audio Signals</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+New+Phase+Vocoder+Technique+for+Time-Scale+Modification+of+Audio+Signals" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1995</td><td>M. Puckette</td><td>Phase-Locked Vocoder</td><td>ICMC</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Phase-Locked+Vocoder" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1990</td><td>X. Serra; J. O. Smith</td><td>Spectral Modeling Synthesis: A Sound Analysis/Synthesis System Based on a Deterministic Plus Stochastic Decomposition</td><td>Computer Music Journal</td><td><code>publisher_or_standard</code></td><td><a href="https://www.jstor.org/stable/3680788" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1989</td><td>R. Bristow-Johnson; M. Bogdanowicz</td><td>Phase Vocoder Done Right</td><td>AES Preprint</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Phase+Vocoder+Done+Right" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1986</td><td>M. Dolson</td><td>The Phase Vocoder: A Tutorial</td><td>Computer Music Journal</td><td><code>publisher_or_standard</code></td><td><a href="https://www.jstor.org/stable/3680093" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1986</td><td>R. J. McAulay; T. F. Quatieri</td><td>Speech Analysis/Synthesis Based on a Sinusoidal Representation</td><td>IEEE Trans. ASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Speech+Analysis%2FSynthesis+Based+on+a+Sinusoidal+Representation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1985</td><td>N. Roucos; A. Wilgus</td><td>High Quality Time-Scale Modification for Speech</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=High+Quality+Time-Scale+Modification+for+Speech" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1984</td><td>D. W. Griffin; J. S. Lim</td><td>Signal Estimation from Modified Short-Time Fourier Transform</td><td>IEEE Trans. ASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASSP.1984.1164317" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1980</td><td>M. R. Portnoff</td><td>Time-Scale Modification of Speech Based on Short-Time Fourier Analysis</td><td>IEEE Trans. ASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Time-Scale+Modification+of+Speech+Based+on+Short-Time+Fourier+Analysis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1977</td><td>J. B. Allen; L. R. Rabiner</td><td>A Unified Approach to Short-Time Fourier Analysis and Synthesis</td><td>Proceedings of the IEEE</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/PROC.1977.10770" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1976</td><td>M. R. Portnoff</td><td>Implementation of the Digital Phase Vocoder Using the Fast Fourier Transform</td><td>IEEE Trans. ASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Implementation+of+the+Digital+Phase+Vocoder+Using+the+Fast+Fourier+Transform" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1966</td><td>J. L. Flanagan; R. M. Golden</td><td>Phase Vocoder</td><td>Bell System Technical Journal</td><td><code>doi</code></td><td><a href="https://doi.org/10.1002/j.1538-7305.1966.tb01706.x" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="time-scale-and-pitch-methods">Time-Scale and Pitch Methods</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2016</td><td>J. Driedger; M. Müller</td><td>A Review of Time-Scale Modification of Music Signals</td><td>Applied Sciences</td><td><code>doi</code></td><td><a href="https://doi.org/10.3390/app6020057" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>M. Riess; A. R. Chhetri</td><td>Transient Preservation in Time-Scale Modification</td><td>WASPAA</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Transient+Preservation+in+Time-Scale+Modification" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2014</td><td>J. Driedger; T. Pratzlich; M. Muller</td><td>Let It Bee - Towards NMF-Inspired Audio Mosaicing</td><td>ISMIR</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Let+It+Bee+-+Towards+NMF-Inspired+Audio+Mosaicing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>M. Le Roux; E. Vincent</td><td>Consistent Wiener Filtering for Audio Source Separation and Time-Frequency Processing</td><td>IEEE Signal Processing Letters</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Consistent+Wiener+Filtering+for+Audio+Source+Separation+and+Time-Frequency+Processing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>D. S. Hamon; A. Lazarides</td><td>Improved WSOLA for Real-Time Time-Scale Modification</td><td>AES Convention</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Improved+WSOLA+for+Real-Time+Time-Scale+Modification" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>A. Roebel</td><td>A Shape-Invariant Phase Vocoder for Speech Transformation</td><td>Interspeech</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Shape-Invariant+Phase+Vocoder+for+Speech+Transformation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2008</td><td>J. Bonada</td><td>Wide-Band Harmonic Sinusoidal Modeling for Time-Scale and Pitch-Scale Modification</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Wide-Band+Harmonic+Sinusoidal+Modeling+for+Time-Scale+and+Pitch-Scale+Modification" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2005</td><td>A. Röbel; X. Rodet</td><td>Efficient Spectral Envelope Estimation and Its Application to Pitch Shifting and Envelope Preservation</td><td>DAFx</td><td><code>web</code></td><td><a href="https://www.dafx.de/paper-archive/2005/P_189.pdf" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2004</td><td>A. de Cheveigne</td><td>Pitch and Time Manipulation of Speech</td><td>Tutorial</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Pitch+and+Time+Manipulation+of+Speech" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2003</td><td>S. M. Bernsee</td><td>Time Stretching and Pitch Shifting of Audio Signals - An Overview</td><td>Online article</td><td><code>web</code></td><td><a href="https://blogs.zynaptiq.com/bernsee/time-pitch-overview/" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2003</td><td>J. Laroche</td><td>About this Phasiness Business</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=About+this+Phasiness+Business" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2002</td><td>S. Arfib; D. Keiler; U. Zölzer</td><td>DAFX: Digital Audio Effects (chapter references on pitch/time processing)</td><td>Wiley</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=DAFX+Digital+Audio+Effects+pitch+shifting+chapter" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1993</td><td>W. Verhelst; M. Roelands</td><td>An Overlap-Add Technique Based on Waveform Similarity (WSOLA) for High Quality Time-Scale Modification of Speech</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=WSOLA+overlap-add+technique+waveform+similarity" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1990</td><td>E. Moulines; F. Charpentier</td><td>Pitch-Synchronous Waveform Processing Techniques for Text-to-Speech Synthesis Using Diphones</td><td>Speech Communication</td><td><code>doi</code></td><td><a href="https://doi.org/10.1016/0167-6393(90)90021-Z" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="pitch-detection-and-tracking">Pitch Detection and Tracking</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2018</td><td>S. Bock; M. Korzeniowski</td><td>piano_transcription - F0 and onset tracking</td><td>ISMIR</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=piano_transcription+-+F0+and+onset+tracking" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>J. W. Kim; J. Salamon; P. Li; J. P. Bello</td><td>CREPE: A Convolutional Representation for Pitch Estimation</td><td>ICASSP</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1802.06182" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2017</td><td>R. Bittner et al.</td><td>Deep Salience Representations for F0 Estimation in Polyphonic Music</td><td>ISMIR</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1706.02292" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>B. W. Schuller et al.</td><td>Paralinguistics and robust pitch tracking methods</td><td>IEEE</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Paralinguistics+and+robust+pitch+tracking+methods" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2014</td><td>M. Mauch; S. Dixon</td><td>pYIN: A Fundamental Frequency Estimator Using Probabilistic Threshold Distributions</td><td>ICASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/ICASSP.2014.6853678" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>K. Dressler</td><td>Sinusoidal Extraction using Frequency-Domain Matching Pursuit</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Sinusoidal+Extraction+using+Frequency-Domain+Matching+Pursuit" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2008</td><td>A. Camacho; J. G. Harris</td><td>A Sawtooth Waveform Inspired Pitch Estimator for Speech and Music (SWIPE)</td><td>JASA</td><td><code>doi</code></td><td><a href="https://doi.org/10.1121/1.2951592" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2006</td><td>A. Klapuri</td><td>Multiple Fundamental Frequency Estimation by Harmonicity and Spectral Smoothness</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Multiple+Fundamental+Frequency+Estimation+by+Harmonicity+and+Spectral+Smoothness" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2005</td><td>M. McLeod; G. Wyvill</td><td>A Smarter Way to Find Pitch</td><td>ICMC</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Smarter+Way+to+Find+Pitch" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2002</td><td>A. de Cheveigné; H. Kawahara</td><td>YIN, a Fundamental Frequency Estimator for Speech and Music</td><td>JASA</td><td><code>doi</code></td><td><a href="https://doi.org/10.1121/1.1458024" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>H. Kawahara; A. de Cheveigne</td><td>STRAIGHT, Exploitation of the Other Aspects of Vocal Source Information</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=STRAIGHT%2C+Exploitation+of+the+Other+Aspects+of+Vocal+Source+Information" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2000</td><td>S. Kum; C. L. Nikias</td><td>Robust F0 Estimation in Noise</td><td>IEEE</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Robust+F0+Estimation+in+Noise" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>S. Ahmadi; H. Spanias</td><td>Cepstrum-Based Pitch Detection Using FFT</td><td>Conference</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Cepstrum-Based+Pitch+Detection+Using+FFT" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1995</td><td>D. Talkin</td><td>A Robust Algorithm for Pitch Tracking (RAPT)</td><td>In Speech Coding and Synthesis</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Robust+Algorithm+for+Pitch+Tracking+RAPT" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1993</td><td>P. Boersma</td><td>Accurate Short-Term Analysis of the Fundamental Frequency and the Harmonics-to-Noise Ratio of a Sampled Sound</td><td>IFA Proceedings</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Accurate+Short-Term+Analysis+of+the+Fundamental+Frequency+and+the+Harmonics-to-Noise+Ratio" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1976</td><td>L. R. Rabiner; M. J. Cheng; A. E. Rosenberg; C. A. McGonegal</td><td>A Comparative Performance Study of Several Pitch Detection Algorithms</td><td>IEEE Trans. ASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Comparative+Performance+Study+of+Several+Pitch+Detection+Algorithms" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1967</td><td>A. M. Noll</td><td>Cepstrum Pitch Determination</td><td>JASA</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Cepstrum+Pitch+Determination" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="time-frequency-and-transform-methods">Time-Frequency and Transform Methods</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2019</td><td>M. Doring; M. M. Kokuer</td><td>Practical NSGT audio applications</td><td>DAFx</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Practical+NSGT+audio+applications" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>S. Essid; G. Richard</td><td>Musical signal analysis with reassignment methods</td><td>Book chapter</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Musical+signal+analysis+with+reassignment+methods" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>I. Daubechies; J. Lu; H.-T. Wu</td><td>Synchrosqueezed Wavelet Transforms</td><td>Applied and Computational Harmonic Analysis</td><td><code>doi</code></td><td><a href="https://doi.org/10.1016/j.acha.2010.08.002" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>G. Velasco; N. Holighaus; M. Dörfler; T. Grill</td><td>Constructing an Invertible Constant-Q Transform with Nonstationary Gabor Frames</td><td>DAFx</td><td><code>web</code></td><td><a href="https://grrrr.org/data/publications/2011_VelascoHolighausDorflerGrill_DAFx.pdf" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>A. V. Oppenheim; R. W. Schafer</td><td>Discrete-Time Signal Processing (STFT and filter-bank chapters)</td><td>Pearson</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Discrete-Time+Signal+Processing+%28STFT+and+filter-bank+chapters%29" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>C. Schörkhuber; A. Klapuri</td><td>Constant-Q Transform Toolbox for Music Processing</td><td>SMC</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Constant-Q+Transform+Toolbox+for+Music+Processing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2006</td><td>A. C. Gilbert; M. J. Strauss</td><td>Approximation of signals in sparse Fourier dictionaries</td><td>IEEE</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Approximation+of+signals+in+sparse+Fourier+dictionaries" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2002</td><td>P. Flandrin; F. Auger; E. Chassande-Mottin</td><td>Time-Frequency Reassignment: From Principles to Algorithms</td><td>Applications in Time-Frequency Signal Processing</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency+Reassignment%3A+From+Principles+to+Algorithms" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>K. Grochenig</td><td>Foundations of Time-Frequency Analysis</td><td>Birkhauser</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Foundations+of+Time-Frequency+Analysis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1998</td><td>P. Flandrin</td><td>Time-Frequency/Time-Scale Analysis</td><td>Academic Press</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency%2FTime-Scale+Analysis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1995</td><td>F. Auger; P. Flandrin</td><td>Improving the Readability of Time-Frequency and Time-Scale Representations by the Reassignment Method</td><td>IEEE Trans. SP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/78.382394" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1995</td><td>D. L. Donoho</td><td>De-Noising by Soft-Thresholding</td><td>IEEE Trans. Information Theory</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=De-Noising+by+Soft-Thresholding" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1993</td><td>S. Mallat; Z. Zhang</td><td>Matching Pursuits with Time-Frequency Dictionaries</td><td>IEEE Trans. Signal Processing</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Matching+Pursuits+with+Time-Frequency+Dictionaries" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1992</td><td>R. R. Coifman; M. V. Wickerhauser</td><td>Entropy-Based Algorithms for Best Basis Selection</td><td>IEEE Trans. IT</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/18.119732" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1992</td><td>J. C. Brown; M. S. Puckette</td><td>An Efficient Algorithm for the Calculation of a Constant Q Transform</td><td>JASA</td><td><code>doi</code></td><td><a href="https://doi.org/10.1121/1.404385" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1991</td><td>S. Mann; S. Haykin</td><td>The Chirplet Transform: Physical Considerations</td><td>IEEE Trans. SP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=The+Chirplet+Transform%3A+Physical+Considerations" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1991</td><td>J. C. Brown</td><td>Calculation of a Constant Q Spectral Transform</td><td>JASA</td><td><code>doi</code></td><td><a href="https://doi.org/10.1121/1.400476" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1989</td><td>L. Cohen</td><td>Time-Frequency Distributions - A Review</td><td>Proceedings of the IEEE</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency+Distributions+-+A+Review" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1989</td><td>S. Mallat</td><td>A Theory for Multiresolution Signal Decomposition: The Wavelet Representation</td><td>IEEE Trans. PAMI</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/34.192463" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="separation-and-decomposition">Separation and Decomposition</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2019</td><td>J. Le Roux; S. Wisdom; H. Erdogan; J. R. Hershey</td><td>SDR half-baked or well done?</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=SDR+half-baked+or+well+done%3F" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>F.-R. Stöter; S. Uhlich; A. Liutkus; Y. Mitsufuji</td><td>Open-Unmix - A Reference Implementation for Music Source Separation</td><td>Journal of Open Source Software</td><td><code>doi</code></td><td><a href="https://doi.org/10.21105/joss.01667" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>F.-R. Stoter; S. Uhlich; A. Liutkus; Y. Mitsufuji</td><td>Open-Unmix</td><td>ISMIR</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Open-Unmix" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>A. Défossez et al.</td><td>Music Source Separation in the Waveform Domain</td><td>arXiv</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1911.13254" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>A. Defossez et al.</td><td>Music Source Separation in the Waveform Domain</td><td>ISMIR</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Music+Source+Separation+in+the+Waveform+Domain" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>N. Takahashi et al.</td><td>MMDenseLSTM for source separation</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=MMDenseLSTM+for+source+separation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2017</td><td>A. Jansson et al.</td><td>Singing Voice Separation with Deep U-Net Convolutional Networks</td><td>ISMIR</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1706.09088" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>N. Ono</td><td>Stable and fast update rules for independent low-rank matrix analysis based on auxiliary function technique</td><td>WASPAA</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Stable+and+fast+update+rules+for+independent+low-rank+matrix+analysis+based+on+auxiliary+function+technique" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>E. J. Candès; X. Li; Y. Ma; J. Wright</td><td>Robust Principal Component Analysis?</td><td>JACM</td><td><code>doi</code></td><td><a href="https://doi.org/10.1145/1970392.1970395" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>E. J. Candes; X. Li; Y. Ma; J. Wright</td><td>Robust Principal Component Analysis?</td><td>Journal of ACM</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Robust+Principal+Component+Analysis%3F" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>D. Fitzgerald</td><td>Harmonic/Percussive Separation Using Median Filtering</td><td>DAFx</td><td><code>web</code></td><td><a href="https://www.dafx.de/paper-archive/2010/DAFx10/Rx35.pdf" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2009</td><td>C. Fevotte; N. Bertin; J.-L. Durrieu</td><td>Nonnegative Matrix Factorization with the Itakura-Saito Divergence</td><td>Neural Computation</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Nonnegative+Matrix+Factorization+with+the+Itakura-Saito+Divergence" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2007</td><td>T. Virtanen</td><td>Monaural Sound Source Separation by Nonnegative Matrix Factorization with Temporal Continuity and Sparseness Criteria</td><td>IEEE Trans. Audio, Speech, and Language Processing</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Monaural+sound+source+separation+by+nonnegative+matrix+factorization+with+temporal+continuity+and+sparseness+criteria" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2007</td><td>P. Smaragdis</td><td>Convolutive Speech Bases and Their Application to Supervised Speech Separation</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Convolutive+Speech+Bases+and+Their+Application+to+Supervised+Speech+Separation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>D. D. Lee; H. S. Seung</td><td>Algorithms for Non-negative Matrix Factorization</td><td>NIPS</td><td><code>doi</code></td><td><a href="https://doi.org/10.1162/089976601750541778" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2000</td><td>A. Hyvärinen; E. Oja</td><td>Independent Component Analysis: Algorithms and Applications</td><td>Neural Networks</td><td><code>doi</code></td><td><a href="https://doi.org/10.1016/S0893-6080(00)00026-5" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2000</td><td>A. Hyvarinen; E. Oja</td><td>Independent Component Analysis: Algorithms and Applications</td><td>Neural Networks</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Independent+Component+Analysis%3A+Algorithms+and+Applications" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>D. D. Lee; H. S. Seung</td><td>Learning the Parts of Objects by Non-negative Matrix Factorization</td><td>Nature</td><td><code>doi</code></td><td><a href="https://doi.org/10.1038/44565" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>A. Hyvärinen</td><td>Fast and Robust Fixed-Point Algorithms for Independent Component Analysis</td><td>IEEE Trans. Neural Networks</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/72.761722" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1995</td><td>A. J. Bell; T. J. Sejnowski</td><td>An Information-Maximization Approach to Blind Separation and Blind Deconvolution</td><td>Neural Computation</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=An+Information-Maximization+Approach+to+Blind+Separation+and+Blind+Deconvolution" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1994</td><td>P. Comon</td><td>Independent Component Analysis, A New Concept?</td><td>Signal Processing</td><td><code>doi</code></td><td><a href="https://doi.org/10.1016/0165-1684(94)90029-9" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="denoising-dereverberation-and-spatial-audio">Denoising, Dereverberation, and Spatial Audio</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2023</td><td>EBU</td><td>EBU R128: Loudness Normalisation and Permitted Maximum Level of Audio Signals</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://tech.ebu.ch/publications/r128" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>M. H. C. de Gesmundo et al.</td><td>ViSQOL v3: An Open Source Production Ready Objective Speech and Audio Metric</td><td>QoMEX</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=ViSQOL+v3+objective+speech+and+audio+metric" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>A. Pandey; D. Wang</td><td>A New Framework for CNN-Based Speech Enhancement in the Time Domain</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+New+Framework+for+CNN-Based+Speech+Enhancement+in+the+Time+Domain" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>N. W. D. Evans et al.</td><td>The voicehome and CHiME challenges</td><td>IEEE</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=The+voicehome+and+CHiME+challenges" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>J.-M. Valin</td><td>A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement (RNNoise)</td><td>MMSP / arXiv</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1709.08243" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>J.-M. Valin</td><td>A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement</td><td>MMSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Hybrid+DSP%2FDeep+Learning+Approach+to+Real-Time+Full-Band+Speech+Enhancement" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2016</td><td>K. Kinoshita et al.</td><td>A summary of the REVERB challenge</td><td>EURASIP Journal</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+summary+of+the+REVERB+challenge" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>ITU-R</td><td>BS.1770-4: Algorithms to Measure Audio Programme Loudness and True-Peak Audio Level</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://www.itu.int/rec/R-REC-BS.1770" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>S. Doclo et al.</td><td>Acoustic beamforming for hearing aid applications</td><td>Handbook</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Acoustic+beamforming+for+hearing+aid+applications" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2013</td><td>P. C. Loizou</td><td>Speech Enhancement: Theory and Practice</td><td>CRC Press</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement%3A+Theory+and+Practice" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>A. Hines et al.</td><td>VISQOL: An Objective Speech Quality Model</td><td>EURASIP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=VISQOL%3A+An+Objective+Speech+Quality+Model" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>N. D. Gaubitch; P. A. Naylor</td><td>Speech Dereverberation</td><td>Springer Handbook</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Speech+Dereverberation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>Y. Yoshioka; T. Nakatani</td><td>Generalization of Multi-Channel Linear Prediction Methods for Blind MIMO Impulse Response Shortening</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Generalization+of+Multi-Channel+Linear+Prediction+Methods+for+Blind+MIMO+Impulse+Response+Shortening" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>T. Yoshioka; T. Nakatani</td><td>Generalization of Multi-Channel Linear Prediction Methods for Blind MIMO Impulse Response Shortening</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Generalization+of+Multi-Channel+Linear+Prediction+Methods+for+Blind+MIMO+Impulse+Response+Shortening" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>K. K. Paliwal</td><td>Importance of phase in speech enhancement</td><td>Speech Communication</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Importance+of+phase+in+speech+enhancement" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>C. H. Taal; R. C. Hendriks; R. Heusdens; J. Jensen</td><td>An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech (STOI)</td><td>IEEE TASLP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASL.2010.2089940" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>C. Taal et al.</td><td>An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech</td><td>IEEE TASLP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=An+Algorithm+for+Intelligibility+Prediction+of+Time-Frequency+Weighted+Noisy+Speech" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2010</td><td>T. Nakatani; M. Miyoshi; K. Kinoshita</td><td>Speech Dereverberation Based on Variance-Normalized Delayed Linear Prediction</td><td>IEEE Trans. Audio, Speech, and Language Processing</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASL.2010.2052251" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>I. Cohen; B. Berdugo</td><td>Speech Enhancement for Non-Stationary Noise Environments</td><td>Signal Processing</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement+for+Non-Stationary+Noise+Environments" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>A. W. Rix; J. G. Beerends; M. P. Hollier; A. P. Hekstra</td><td>Perceptual Evaluation of Speech Quality (PESQ)</td><td>ICASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/ICASSP.2001.941023" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>A. Rix et al.</td><td>Perceptual Evaluation of Speech Quality (PESQ)</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Perceptual+Evaluation+of+Speech+Quality+%28PESQ%29" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>R. Martin</td><td>Noise Power Spectral Density Estimation Based on Optimal Smoothing and Minimum Statistics</td><td>IEEE Trans. Speech and Audio Processing</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/89.917870" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1997</td><td>S. Pulkki</td><td>Virtual Sound Source Positioning Using Vector Base Amplitude Panning</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Virtual+Sound+Source+Positioning+Using+Vector+Base+Amplitude+Panning" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1996</td><td>P. Scalart; J. V. Filho</td><td>Speech Enhancement Based on a Priori Signal to Noise Estimation</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement+Based+on+a+Priori+Signal+to+Noise+Estimation" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1985</td><td>Y. Ephraim; D. Malah</td><td>Speech Enhancement Using a Minimum Mean-Square Error Log-Spectral Amplitude Estimator</td><td>IEEE Trans. ASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASSP.1985.1164550" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1984</td><td>Y. Ephraim; D. Malah</td><td>Speech Enhancement Using a Minimum Mean-Square Error Short-Time Spectral Amplitude Estimator</td><td>IEEE Trans. ASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASSP.1984.1164453" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1982</td><td>L. J. Griffiths; C. W. Jim</td><td>An Alternative Approach to Linearly Constrained Adaptive Beamforming</td><td>IEEE Trans. Antennas and Propagation</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TAP.1982.1142739" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1979</td><td>S. F. Boll</td><td>Suppression of Acoustic Noise in Speech Using Spectral Subtraction</td><td>IEEE Trans. ASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASSP.1979.1163209" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1979</td><td>S. Boll</td><td>Suppression of Acoustic Noise in Speech Using Spectral Subtraction</td><td>IEEE TASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Suppression+of+Acoustic+Noise+in+Speech+Using+Spectral+Subtraction" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1976</td><td>C. Knapp; G. Carter</td><td>The Generalized Correlation Method for Estimation of Time Delay</td><td>IEEE Trans. ASSP</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/TASSP.1976.1162830" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1972</td><td>O. L. Frost III</td><td>An Algorithm for Linearly Constrained Adaptive Array Processing</td><td>Proceedings of the IEEE</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/PROC.1972.8817" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1969</td><td>J. Capon</td><td>High-Resolution Frequency-Wavenumber Spectrum Analysis</td><td>Proceedings of the IEEE</td><td><code>doi</code></td><td><a href="https://doi.org/10.1109/PROC.1969.7278" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1949</td><td>N. Wiener</td><td>Extrapolation, Interpolation, and Smoothing of Stationary Time Series</td><td>Book</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Extrapolation+Interpolation+and+Smoothing+of+Stationary+Time+Series+Wiener" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="spatial-audio-beamforming-and-ambisonics">Spatial Audio, Beamforming, and Ambisonics</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2019</td><td>F. Zotter; M. Frank</td><td>Ambisonics: A Practical 3D Audio Theory</td><td>Springer</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Ambisonics%3A+A+Practical+3D+Audio+Theory" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>A. Politis et al.</td><td>A Dataset of Binaural Room Impulse Responses for Evaluation of Spatial Audio Algorithms</td><td>AES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Dataset+of+Binaural+Room+Impulse+Responses+for+Evaluation+of+Spatial+Audio+Algorithms" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>B. Rafaely</td><td>Fundamentals of Spherical Array Processing</td><td>Springer</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Fundamentals+of+Spherical+Array+Processing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2008</td><td>J. Benesty; J. Chen; Y. Huang</td><td>Microphone Array Signal Processing</td><td>Springer</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Microphone+Array+Signal+Processing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2006</td><td>S. Spors; R. Rabenstein</td><td>Spatial Sound Reproduction by Wave Field Synthesis</td><td>European Signal Processing Conference</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Spatial+Sound+Reproduction+by+Wave+Field+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2006</td><td>E. A. P. Habets</td><td>Room Impulse Response Generator</td><td>TU Eindhoven</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Room+Impulse+Response+Generator" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2005</td><td>M. Poletti</td><td>Three-Dimensional Surround Sound Systems Based on Spherical Harmonics</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Three-Dimensional+Surround+Sound+Systems+Based+on+Spherical+Harmonics" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2005</td><td>M. A. Poletti</td><td>A Unified Theory of Horizontal Holographic and Ambisonic Sound Systems</td><td>Acta Acustica</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Unified+Theory+of+Horizontal+Holographic+and+Ambisonic+Sound+Systems" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2002</td><td>H. L. Van Trees</td><td>Optimum Array Processing</td><td>Wiley</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Optimum+Array+Processing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>J. Daniel</td><td>Spatial Sound Encoding Including Near Field Effect</td><td>AES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Spatial+Sound+Encoding+Including+Near+Field+Effect" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>M. Brandstein; D. Ward</td><td>Microphone Arrays: Signal Processing Techniques and Applications</td><td>Springer</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Microphone+Arrays%3A+Signal+Processing+Techniques+and+Applications" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2001</td><td>P. Minnaar et al.</td><td>A Localization Model for Binaural Rendering</td><td>AES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Localization+Model+for+Binaural+Rendering" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2000</td><td>A. Farina</td><td>Simultaneous Measurement of Impulse Response and Distortion with a Swept-Sine Technique</td><td>AES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Simultaneous+Measurement+of+Impulse+Response+and+Distortion+with+a+Swept-Sine+Technique" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1999</td><td>W. M. Hartmann</td><td>How We Localize Sound</td><td>Physics Today</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=How+We+Localize+Sound" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1997</td><td>V. Pulkki</td><td>Virtual Sound Source Positioning Using Vector Base Amplitude Panning</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Virtual+Sound+Source+Positioning+Using+Vector+Base+Amplitude+Panning" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1997</td><td>J. Blauert</td><td>Spatial Hearing</td><td>MIT Press</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Spatial+Hearing" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1997</td><td>M. S. Brandstein</td><td>A Pitch-Based Real-Time Tracking of Speech Source</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Pitch-Based+Real-Time+Tracking+of+Speech+Source" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1985</td><td>M. A. Gerzon</td><td>Ambisonics in Multichannel Broadcasting and Video</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Ambisonics+in+Multichannel+Broadcasting+and+Video" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1982</td><td>L. Griffiths; C. Jim</td><td>An Alternative Approach to Linearly Constrained Adaptive Beamforming</td><td>IEEE Trans. AP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=An+Alternative+Approach+to+Linearly+Constrained+Adaptive+Beamforming" target="_blank" rel="noopener">Link</a></td></tr><tr><td>1973</td><td>M. A. Gerzon</td><td>Periphony: With-Height Sound Reproduction</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Periphony%3A+With-Height+Sound+Reproduction" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="loudness-dynamics-and-mastering">Loudness, Dynamics, and Mastering</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2023</td><td>EBU</td><td>Tech 3343: Production Guidelines</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://tech.ebu.ch/publications/tech3343" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2023</td><td>EBU</td><td>Tech 3342: Loudness Range</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://tech.ebu.ch/publications/tech3342" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2023</td><td>EBU</td><td>Tech 3341: Loudness Metering: EBU Mode</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://tech.ebu.ch/publications/tech3341" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2023</td><td>ITU-R</td><td>BS.1770-5: Algorithms to Measure Audio Programme Loudness and True-Peak Audio Level</td><td>Recommendation</td><td><code>publisher_or_standard</code></td><td><a href="https://www.itu.int/rec/R-REC-BS.1770" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2020</td><td>S. Stables et al.</td><td>A Study of Loudness Normalization in Streaming Services</td><td>AES Convention</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=A+Study+of+Loudness+Normalization+in+Streaming+Services" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>M. Fenton</td><td>Practical Dynamics Processing for Modern Music Production</td><td>AES Tutorial</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Practical+Dynamics+Processing+for+Modern+Music+Production" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2015</td><td>M. Ballou</td><td>Handbook for Sound Engineers (Loudness and Dynamics chapters)</td><td>CRC Press</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Handbook+for+Sound+Engineers+%28Loudness+and+Dynamics+chapters%29" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2012</td><td>D. Giannoulis; M. Massberg; J. Reiss</td><td>Digital Dynamic Range Compressor Design</td><td>JAES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Digital+Dynamic+Range+Compressor+Design" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2011</td><td>J. Reiss</td><td>Under the Hood of a Dynamic Range Compressor</td><td>AES</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Under+the+Hood+of+a+Dynamic+Range+Compressor" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2007</td><td>T. Lund</td><td>Loudness and True-Peak in Digital Audio</td><td>TC Electronic Whitepaper</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Loudness+and+True-Peak+in+Digital+Audio" target="_blank" rel="noopener">Link</a></td></tr></tbody></table>
<h2 id="ml-audio-and-neural-vocoding">ML Audio and Neural Vocoding</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>Venue</th><th>Link type</th><th>Link</th></tr></thead><tbody><tr><td>2021</td><td>S. Wisdom et al.</td><td>Differentiable Consistency Constraints for Improved Deep Speech Enhancement</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Differentiable+Consistency+Constraints+for+Improved+Deep+Speech+Enhancement" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2020</td><td>J. Kong et al.</td><td>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</td><td>NeurIPS</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=HiFi-GAN%3A+Generative+Adversarial+Networks+for+Efficient+and+High+Fidelity+Speech+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2020</td><td>J. Engel et al.</td><td>DDSP: Differentiable Digital Signal Processing</td><td>ICLR</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/2001.04643" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>R. Prenger et al.</td><td>WaveGlow: A Flow-based Generative Network for Speech Synthesis</td><td>ICASSP</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=WaveGlow%3A+A+Flow-based+Generative+Network+for+Speech+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2019</td><td>K. Kumar et al.</td><td>MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis</td><td>NeurIPS</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=MelGAN%3A+Generative+Adversarial+Networks+for+Conditional+Waveform+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>N. Kalchbrenner et al.</td><td>Efficient Neural Audio Synthesis</td><td>ICML</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Efficient+Neural+Audio+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2018</td><td>C. Donahue; J. McAuley; M. Puckette</td><td>Adversarial Audio Synthesis</td><td>ICLR Workshop</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Adversarial+Audio+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2017</td><td>Y. Wang et al.</td><td>Tacotron: Towards End-to-End Speech Synthesis</td><td>Interspeech</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Tacotron%3A+Towards+End-to-End+Speech+Synthesis" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2017</td><td>A. Gibiansky et al.</td><td>Deep Voice 2: Multi-Speaker Neural Text-to-Speech</td><td>NeurIPS Workshop</td><td><code>scholar</code></td><td><a href="https://scholar.google.com/scholar?q=Deep+Voice+2%3A+Multi-Speaker+Neural+Text-to-Speech" target="_blank" rel="noopener">Link</a></td></tr><tr><td>2016</td><td>A. van den Oord et al.</td><td>WaveNet: A Generative Model for Raw Audio</td><td>ArXiv</td><td><code>arxiv</code></td><td><a href="https://arxiv.org/abs/1609.03499" target="_blank" rel="noopener">Link</a></td></tr></tbody></table></main>
  <footer class="site-footer">
    <div class="wrap">
      Generated by <code>scripts_generate_html_docs.py</code> from commit <code>73af302</code>
      (commit date: 2026-02-17T11:13:12-05:00).
    </div>
  </footer>
</body>
</html>
