<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>pvx Technical Glossary</title>
  <link rel="stylesheet" href="style.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
  <header class="site-header">
    <div class="wrap">
      <h1>pvx Technical Glossary</h1>
      <nav><a href="index.html">Home</a> | <a href="papers.html">Research papers</a> | <a href="math.html">Math</a> | <a href="windows.html">Windows</a> | <a href="architecture.html">Architecture</a></nav>
    </div>
  </header>
  <main class="wrap"><div class="card"><h2>Acronym primer</h2><ul><li>application programming interface (API)</li><li>command-line interface (CLI)</li><li>path environment variable (PATH)</li><li>digital signal processing (DSP)</li><li>short-time Fourier transform (STFT)</li><li>inverse short-time Fourier transform (ISTFT)</li><li>fast Fourier transform (FFT)</li><li>discrete Fourier transform (DFT)</li><li>central processing unit (CPU)</li><li>graphics processing unit (GPU)</li><li>Compute Unified Device Architecture (CUDA)</li><li>comma-separated values (CSV)</li><li>JavaScript Object Notation (JSON)</li><li>HyperText Markup Language (HTML)</li><li>Portable Document Format (PDF)</li><li>continuous integration (CI)</li><li>fundamental frequency (F0)</li><li>waveform similarity overlap-add (WSOLA)</li><li>input/output (I/O)</li><li>root-mean-square (RMS)</li><li>loudness units relative to full scale (LUFS)</li><li>signal-to-noise ratio (SNR)</li></ul></div>
<div class="card">
  <p>
    Linked glossary for core concepts used throughout pvx algorithms, CLIs, and research docs.
    Entries include concise definitions plus external references (Wikipedia, standards pages,
    project docs, and canonical papers).
  </p>
  <p>
    Total terms: <strong>103</strong> across <strong>10</strong> categories.
  </p>
</div>

<div class="card"><h2>Categories</h2><ul><li><a href="#core-dsp-math">Core DSP Math (15)</a></li><li><a href="#phase-and-time-scale-dsp">Phase and Time-Scale DSP (11)</a></li><li><a href="#pitch-and-intonation">Pitch and Intonation (12)</a></li><li><a href="#time-frequency-transforms">Time-Frequency Transforms (8)</a></li><li><a href="#separation-and-decomposition">Separation and Decomposition (8)</a></li><li><a href="#denoising-and-restoration">Denoising and Restoration (13)</a></li><li><a href="#dynamics-and-mastering">Dynamics and Mastering (10)</a></li><li><a href="#creative-spectral-effects">Creative Spectral Effects (8)</a></li><li><a href="#spatial-audio-and-multichannel">Spatial Audio and Multichannel (10)</a></li><li><a href="#analysis-and-qa">Analysis and QA (8)</a></li></ul></div>
<h2 id="core-dsp-math">Core DSP Math</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="aliasing">Aliasing</td><td>Frequency-domain folding caused by undersampling. Unchecked aliasing folds out-of-band content back into the audible band, often creating false partials or metallic artifacts.</td><td><a href="https://en.wikipedia.org/wiki/Aliasing" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="blackman-window">Blackman window</td><td>Cosine-sum window with stronger sidelobe suppression. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Window_function" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="convolution">Convolution</td><td>Linear filtering operation in time domain equivalent to multiplication in frequency domain. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Convolution" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="fast-fourier-transform-fft">Fast Fourier transform (FFT)</td><td>Efficient algorithm for computing the discrete Fourier transform. Its computational efficiency is critical because pvx repeatedly computes FFTs frame-by-frame across channels and files.</td><td><a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="fourier-transform">Fourier transform</td><td>Transforms a signal from time domain to frequency domain. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Fourier_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="hamming-window">Hamming window</td><td>Cosine-sum window with reduced nearest sidelobe amplitude. Compared with Hann it slightly reduces nearest sidelobes, often at the cost of different amplitude bias characteristics.</td><td><a href="https://en.wikipedia.org/wiki/Window_function" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="hann-window">Hann window</td><td>Raised cosine window commonly used in STFT analysis. It is a common default because it offers a strong practical balance between leakage control and frequency resolution.</td><td><a href="https://en.wikipedia.org/wiki/Window_function" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="inverse-fft-ifft">Inverse FFT (IFFT)</td><td>Inverse operation that reconstructs time-domain samples from spectral bins. Accurate inverse transforms are required to reconstruct low-artifact audio after spectral-domain edits.</td><td><a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="kaiser-window">Kaiser window</td><td>Parametric window controlled by beta parameter. The beta parameter gives explicit control over the width-versus-sidelobe tradeoff, which is useful for task-specific tuning.</td><td><a href="https://en.wikipedia.org/wiki/Kaiser_window" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="linear-phase">Linear phase</td><td>Filter phase response that preserves waveform shape of band-limited signals. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Linear_phase" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="minimum-phase">Minimum phase</td><td>System with minimum group delay for a given magnitude response. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Minimum_phase" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="nyquist-frequency">Nyquist frequency</td><td>Half the sample rate; highest representable frequency in sampled audio. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Nyquist_frequency" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="overlap-add-ola">Overlap-add (OLA)</td><td>Frame-based reconstruction by summing overlapped windowed segments. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Overlap%E2%80%93add_method" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="spectral-leakage">Spectral leakage</td><td>Energy spread across bins due to finite-duration analysis windows. In pvx workflows this directly affects spectral resolution, leakage behavior, and overlap-add reconstruction accuracy in STFT-based processing.</td><td><a href="https://en.wikipedia.org/wiki/Spectral_leakage" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="window-function">Window function</td><td>Tapering function applied before spectral analysis to control leakage. Window shape selection is one of the strongest controls on sidelobe suppression versus main-lobe width.</td><td><a href="https://en.wikipedia.org/wiki/Window_function" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="phase-and-time-scale-dsp">Phase and Time-Scale DSP</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="formant-preservation">Formant preservation</td><td>Preservation of spectral envelope while pitch is changed. This helps avoid chipmunk/monster timbre artifacts when pitch is shifted significantly.</td><td><a href="https://en.wikipedia.org/wiki/Formant" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="granular-synthesis">Granular synthesis</td><td>Sound synthesis/modification using short grains. In pvx this concept determines how frames are aligned, phases are propagated, and transients are preserved during time-stretch and pitch operations.</td><td><a href="https://en.wikipedia.org/wiki/Granular_synthesis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="hpss">HPSS</td><td>Harmonic-percussive source separation in TF domain. Harmonic and percussive components can then be processed with different settings to preserve punch while shaping sustain.</td><td><a href="https://scholar.google.com/scholar?q=harmonic+percussive+source+separation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="identity-phase-locking">Identity phase locking</td><td>Phase-locking variant that follows dominant peaks. In pvx this concept determines how frames are aligned, phases are propagated, and transients are preserved during time-stretch and pitch operations.</td><td><a href="https://scholar.google.com/scholar?q=identity+phase+locking" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="lp-psola">LP-PSOLA</td><td>Linear-prediction-assisted PSOLA variant. Linear-prediction support can improve source/filter control and reduce timbral drift in speech-like material.</td><td><a href="https://scholar.google.com/scholar?q=LP-PSOLA" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="phase-locking">Phase locking</td><td>Locking neighboring bin phases to preserve local waveform structure. Locking strategies reduce local phase incoherence, improving clarity and reducing chorus-like blur in stretched material.</td><td><a href="https://scholar.google.com/scholar?q=phase+locking+in+phase+vocoder" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="phase-vocoder">Phase vocoder</td><td>STFT-based time-scale/pitch framework using phase propagation. It underpins most pvx core transforms by decoupling time-scale and pitch behavior through phase-consistent spectral resynthesis.</td><td><a href="https://en.wikipedia.org/wiki/Phase_vocoder" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="td-psola">TD-PSOLA</td><td>Time-domain pitch-synchronous overlap-add technique. It is effective for voiced monophonic content where pitch periods are trackable and edits should remain time-domain natural.</td><td><a href="https://en.wikipedia.org/wiki/Audio_time_stretching_and_pitch_scaling" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="time-warp-map">Time warp map</td><td>Piecewise mapping from output time to input time. In pvx this concept determines how frames are aligned, phases are propagated, and transients are preserved during time-stretch and pitch operations.</td><td><a href="https://scholar.google.com/scholar?q=nonlinear+time+warping+audio" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="transient-preservation">Transient preservation</td><td>Strategies that protect attacks during spectral time modification. Without transient-aware handling, attacks can smear, so this is central for drums and articulation-critical material.</td><td><a href="https://en.wikipedia.org/wiki/Transient_(acoustics)" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="wsola">WSOLA</td><td>Waveform-similarity overlap-add time-scale modification. It is often preferred for moderate speech/music time changes when waveform continuity is more important than heavy spectral editing.</td><td><a href="https://en.wikipedia.org/wiki/Audio_time_stretching_and_pitch_scaling" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="pitch-and-intonation">Pitch and Intonation</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="cents">Cents</td><td>Logarithmic pitch interval unit (1200 cents per octave). Because cents are logarithmic, fixed cent offsets represent musically consistent relative pitch intervals anywhere in the register.</td><td><a href="https://en.wikipedia.org/wiki/Cent_(music)" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="equal-temperament">Equal temperament</td><td>Tuning system dividing octave into equal semitone ratios. It is the default modern tuning grid but may be intentionally replaced for historical or microtonal work.</td><td><a href="https://en.wikipedia.org/wiki/Equal_temperament" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="harmonic-product-spectrum">Harmonic product spectrum</td><td>Downsample-and-multiply spectrum for F0 evidence. In pvx retune pipelines this governs pitch-target decisions, microtonal mapping behavior, and the stability of note-to-note correction.</td><td><a href="https://scholar.google.com/scholar?q=harmonic+product+spectrum+pitch" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="just-intonation">Just intonation</td><td>Tuning based on low-integer frequency ratios. Its pure-ratio intervals can sound more consonant in context but depend strongly on key and harmonic function.</td><td><a href="https://en.wikipedia.org/wiki/Just_intonation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="midi-tuning-standard">MIDI Tuning Standard</td><td>Specification for non-12TET tuning in MIDI systems. This enables compatible systems to exchange alternate tunings without redefining note identities.</td><td><a href="https://en.wikipedia.org/wiki/MIDI_tuning_standard" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="portamento">Portamento</td><td>Continuous slide between notes. Retune systems often need slide-aware logic so expressive glides are not flattened into abrupt quantized jumps.</td><td><a href="https://en.wikipedia.org/wiki/Portamento" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="pyin">pYIN</td><td>Probabilistic extension of YIN with voicing model. Its probabilistic voicing model can improve contour stability relative to raw framewise estimates.</td><td><a href="https://librosa.org/doc/main/generated/librosa.pyin.html" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="rapt">RAPT</td><td>Robust algorithm for pitch tracking. In pvx retune pipelines this governs pitch-target decisions, microtonal mapping behavior, and the stability of note-to-note correction.</td><td><a href="https://scholar.google.com/scholar?q=RAPT+pitch+tracking" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="scala-scale-format">Scala scale format</td><td>Text format for microtonal scales. Using Scala files allows precise import of non-12TET interval maps into repeatable production workflows.</td><td><a href="https://www.huygens-fokker.org/scala/" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="subharmonic-summation">Subharmonic summation</td><td>Weighted subharmonic summation for F0 estimation. In pvx retune pipelines this governs pitch-target decisions, microtonal mapping behavior, and the stability of note-to-note correction.</td><td><a href="https://scholar.google.com/scholar?q=subharmonic+summation+pitch" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="swipe">SWIPE</td><td>Sawtooth-waveform inspired pitch estimator. It emphasizes sawtooth-like harmonic structure, which can improve robustness on certain voiced spectra.</td><td><a href="https://doi.org/10.1121/1.2951592" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="yin">YIN</td><td>Fundamental-frequency estimator using difference-function minima. It is commonly used as a robust baseline detector for monophonic F0 tracks.</td><td><a href="https://librosa.org/doc/main/generated/librosa.yin.html" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="time-frequency-transforms">Time-Frequency Transforms</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="chirplet-transform">Chirplet transform</td><td>Transform using chirped atoms. In pvx transform modules this shapes the tradeoff between time localization, frequency precision, and invertibility of analysis/resynthesis steps.</td><td><a href="https://en.wikipedia.org/wiki/Chirplet_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="constant-q-transform-cqt">Constant-Q transform (CQT)</td><td>Transform with logarithmic center frequencies and constant Q. Its logarithmic spacing is especially useful for music analysis where pitch perception is logarithmic.</td><td><a href="https://en.wikipedia.org/wiki/Constant-Q_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="multiresolution-analysis">Multiresolution analysis</td><td>Nested subspace structure for multi-scale representations. In pvx transform modules this shapes the tradeoff between time localization, frequency precision, and invertibility of analysis/resynthesis steps.</td><td><a href="https://en.wikipedia.org/wiki/Multiresolution_analysis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="nsgt">NSGT</td><td>Nonstationary Gabor transform with invertible adaptive filter banks. NSGT offers adaptive, invertible filter-bank behavior beyond fixed-resolution STFT framing.</td><td><a href="https://scholar.google.com/scholar?q=nonstationary+gabor+transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="reassigned-spectrogram">Reassigned spectrogram</td><td>Sharper TF representation by moving energy to local centroids. Reassignment can sharpen time-frequency energy localization for clearer ridge and onset interpretation.</td><td><a href="https://en.wikipedia.org/wiki/Reassignment_method" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="synchrosqueezing">Synchrosqueezing</td><td>Post-processing that concentrates TF energy along ridges. It can concentrate ridge energy for improved instantaneous-frequency interpretation.</td><td><a href="https://en.wikipedia.org/wiki/Wavelet_transform#Synchrosqueezing_transform" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="variable-q-transform-vqt">Variable-Q transform (VQT)</td><td>Generalized CQT with variable Q and bandwidth behavior. Compared to CQT, VQT broadens control over Q and bandwidth behavior across frequency ranges.</td><td><a href="https://scholar.google.com/scholar?q=variable-Q+transform+audio" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="wavelet-packet">Wavelet packet</td><td>Hierarchical wavelet decomposition of both low/high branches. It supports multi-band decomposition where both approximation and detail branches are recursively analyzed.</td><td><a href="https://en.wikipedia.org/wiki/Wavelet_packet_decomposition" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="separation-and-decomposition">Separation and Decomposition</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="cp-decomposition">CP decomposition</td><td>Canonical polyadic tensor decomposition. In pvx decomposition workflows this assumption controls source isolation quality, bleed rejection, and the interpretability of separated components.</td><td><a href="https://en.wikipedia.org/wiki/Tensor_rank_decomposition" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="demucs">Demucs</td><td>Deep waveform-domain music source separation architecture. Neural stem separation quality can be high, but behavior depends heavily on training-domain match.</td><td><a href="https://github.com/facebookresearch/demucs" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="ica">ICA</td><td>Blind source separation based on statistical independence. In pvx decomposition workflows this assumption controls source isolation quality, bleed rejection, and the interpretability of separated components.</td><td><a href="https://en.wikipedia.org/wiki/Independent_component_analysis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="nmf">NMF</td><td>Nonnegative factorization of matrices into parts-based components. Factor count and constraints strongly influence whether components are musically meaningful or overly fragmented.</td><td><a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="rpca">RPCA</td><td>Low-rank + sparse decomposition robust to outliers. It is frequently used to separate stable backgrounds from sparse foreground events.</td><td><a href="https://en.wikipedia.org/wiki/Robust_principal_component_analysis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="tensor-decomposition">Tensor decomposition</td><td>Higher-order extension of matrix factorization. In pvx decomposition workflows this assumption controls source isolation quality, bleed rejection, and the interpretability of separated components.</td><td><a href="https://en.wikipedia.org/wiki/Tensor_decomposition" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="tucker-decomposition">Tucker decomposition</td><td>Core tensor with mode matrices factorization. In pvx decomposition workflows this assumption controls source isolation quality, bleed rejection, and the interpretability of separated components.</td><td><a href="https://en.wikipedia.org/wiki/Tucker_decomposition" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="u-net">U-Net</td><td>Encoder-decoder CNN with skip connections. In pvx decomposition workflows this assumption controls source isolation quality, bleed rejection, and the interpretability of separated components.</td><td><a href="https://en.wikipedia.org/wiki/U-Net" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="denoising-and-restoration">Denoising and Restoration</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="blind-deconvolution">Blind deconvolution</td><td>Joint estimation of source and room/filter response. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://en.wikipedia.org/wiki/Blind_deconvolution" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="declick">Declick</td><td>Removal of impulsive click artifacts. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://scholar.google.com/scholar?q=audio+declicking" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="declip">Declip</td><td>Reconstruction of clipped waveform segments. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://scholar.google.com/scholar?q=audio+declipping+sparse+reconstruction" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="dereverberation">Dereverberation</td><td>Suppression of late reverberation components. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://en.wikipedia.org/wiki/Reverberation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="diffusion-model">Diffusion model</td><td>Generative model based on iterative denoising processes. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://en.wikipedia.org/wiki/Diffusion_model" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="direct-to-reverberant-ratio-drr">Direct-to-reverberant ratio (DRR)</td><td>Ratio of direct sound energy to reverberant energy. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://scholar.google.com/scholar?q=direct-to-reverberant+ratio" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="log-mmse">Log-MMSE</td><td>Log-spectral MMSE enhancement estimator. Its log-domain objective often better tracks perceptual sensitivity than raw-amplitude objectives.</td><td><a href="https://scholar.google.com/scholar?q=Log-MMSE+speech+enhancement" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="minimum-statistics">Minimum statistics</td><td>Noise tracking from low percentile/minimum spectral statistics. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://scholar.google.com/scholar?q=minimum+statistics+noise+estimation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="mmse-stsa">MMSE-STSA</td><td>MMSE short-time spectral amplitude estimator. It estimates clean spectral amplitudes from noisy observations while minimizing expected short-time error.</td><td><a href="https://scholar.google.com/scholar?q=MMSE-STSA" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="rnnoise">RNNoise</td><td>Hybrid recurrent neural + DSP speech denoiser. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://github.com/xiph/rnnoise" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="spectral-subtraction">Spectral subtraction</td><td>Subtracts estimated noise spectrum from noisy signal. In pvx restoration chains this controls denoise or dereverb strength versus artifact risk, helping balance intelligibility and texture retention.</td><td><a href="https://en.wikipedia.org/wiki/Spectral_subtraction" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="weighted-prediction-error-wpe">Weighted prediction error (WPE)</td><td>Multi-channel dereverb by delayed linear prediction. WPE is a standard dereverberation baseline for suppressing late reverberant tails in multichannel settings.</td><td><a href="https://nara-wpe.readthedocs.io/en/latest/" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="wiener-filter">Wiener filter</td><td>MMSE linear estimator for noisy observations. It is a classic linear MMSE approach and still valuable as a reliable baseline enhancer.</td><td><a href="https://en.wikipedia.org/wiki/Wiener_filter" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="dynamics-and-mastering">Dynamics and Mastering</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="compander">Compander</td><td>Combined compressor and expander behavior. In pvx mastering stages this affects loudness compliance, peak containment, and perceived punch versus transparency across final renders.</td><td><a href="https://en.wikipedia.org/wiki/Companding" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="compressor">Compressor</td><td>Dynamic range processor that reduces gain above threshold. Threshold, ratio, attack, and release jointly define how quickly and how strongly level is controlled.</td><td><a href="https://en.wikipedia.org/wiki/Dynamic_range_compression" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="ebu-r128">EBU R128</td><td>European loudness standard for production and broadcast. R128 operationalizes BS.1770 loudness measurement into practical broadcast and production targets.</td><td><a href="https://tech.ebu.ch/publications/r128" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="expander">Expander</td><td>Dynamic processor that reduces gain below threshold. It can reduce low-level noise floors and room tail audibility by attenuating content below threshold.</td><td><a href="https://en.wikipedia.org/wiki/Expander_(audio)" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="hard-clipping">Hard clipping</td><td>Abrupt saturation by truncating waveform beyond threshold. In pvx mastering stages this affects loudness compliance, peak containment, and perceived punch versus transparency across final renders.</td><td><a href="https://en.wikipedia.org/wiki/Clipping_(audio)" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="itu-r-bs-1770">ITU-R BS.1770</td><td>International loudness measurement recommendation. Its weighting and gating model is the industry baseline for objective integrated loudness measurement.</td><td><a href="https://www.itu.int/rec/R-REC-BS.1770" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="limiter">Limiter</td><td>High-ratio compressor preventing peaks from exceeding threshold. In mastering chains it is commonly the final safety stage to prevent over-level peaks.</td><td><a href="https://en.wikipedia.org/wiki/Dynamic_range_compression" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="lufs">LUFS</td><td>Loudness unit relative to full scale. Targeting LUFS helps keep perceived program loudness consistent across tracks and delivery contexts.</td><td><a href="https://en.wikipedia.org/wiki/LKFS" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="soft-clipping">Soft clipping</td><td>Smooth saturation curve reducing harsh distortion. In pvx mastering stages this affects loudness compliance, peak containment, and perceived punch versus transparency across final renders.</td><td><a href="https://en.wikipedia.org/wiki/Waveshaper" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="true-peak">True peak</td><td>Peak estimate including inter-sample overs. True-peak metering estimates inter-sample peaks that sample-peak meters can miss.</td><td><a href="https://en.wikipedia.org/wiki/Peak_programme_meter" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="creative-spectral-effects">Creative Spectral Effects</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="amplitude-modulation-am">Amplitude modulation (AM)</td><td>Modulating signal amplitude by a control waveform. In pvx creative processing this primarily controls intentional timbral coloration and motion, not transparent corrective behavior.</td><td><a href="https://en.wikipedia.org/wiki/Amplitude_modulation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="cross-synthesis">Cross synthesis</td><td>Combining spectral magnitude and phase or envelopes across signals. Different choices of magnitude/phase or envelope transfer produce very different timbral identities.</td><td><a href="https://en.wikipedia.org/wiki/Cross-synthesis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="formant">Formant</td><td>Resonance region of spectral envelope. In pvx creative processing this primarily controls intentional timbral coloration and motion, not transparent corrective behavior.</td><td><a href="https://en.wikipedia.org/wiki/Formant" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="frequency-modulation-fm">Frequency modulation (FM)</td><td>Modulating oscillator frequency by another signal. In pvx creative processing this primarily controls intentional timbral coloration and motion, not transparent corrective behavior.</td><td><a href="https://en.wikipedia.org/wiki/Frequency_modulation_synthesis" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="lfo">LFO</td><td>Low-frequency oscillator used for modulation. In pvx creative processing this primarily controls intentional timbral coloration and motion, not transparent corrective behavior.</td><td><a href="https://en.wikipedia.org/wiki/Low-frequency_oscillation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="resonator">Resonator</td><td>Filter structure emphasizing a narrow band. In pvx creative processing this primarily controls intentional timbral coloration and motion, not transparent corrective behavior.</td><td><a href="https://en.wikipedia.org/wiki/Resonance" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="ring-modulation">Ring modulation</td><td>Multiplication by a carrier to produce sidebands. Sideband generation can create inharmonic or bell-like textures depending on carrier/modulator relationships.</td><td><a href="https://en.wikipedia.org/wiki/Ring_modulation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="spectral-freezing">Spectral freezing</td><td>Holding a short-time spectrum and resynthesizing over time. Freeze methods hold a selected spectral snapshot and are useful for drones, pads, and transitions.</td><td><a href="https://scholar.google.com/scholar?q=spectral+freeze+effect" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="spatial-audio-and-multichannel">Spatial Audio and Multichannel</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="binaural-rendering">Binaural rendering</td><td>Headphone rendering preserving spatial localization cues. HRTF quality and listener assumptions strongly affect externalization and localization realism.</td><td><a href="https://en.wikipedia.org/wiki/Binaural_recording" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="crosstalk-cancellation">Crosstalk cancellation</td><td>Loudspeaker technique reducing opposite-ear leakage. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://scholar.google.com/scholar?q=transaural+crosstalk+cancellation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="dbap">DBAP</td><td>Distance-based amplitude panning. DBAP generalizes panning by amplitude weighting from geometric distance rather than simplex triplets.</td><td><a href="https://scholar.google.com/scholar?q=distance+based+amplitude+panning+DBAP" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="diffuse-field">Diffuse field</td><td>Sound field with many uncorrelated incoming directions. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://scholar.google.com/scholar?q=diffuse+sound+field" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="hrtf">HRTF</td><td>Head-related transfer function per source direction. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://en.wikipedia.org/wiki/Head-related_transfer_function" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="interaural-level-difference-ild">Interaural level difference (ILD)</td><td>Level difference cue for localization. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://en.wikipedia.org/wiki/Sound_localization" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="interaural-time-difference-itd">Interaural time difference (ITD)</td><td>Arrival-time difference cue for localization. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://en.wikipedia.org/wiki/Interaural_time_difference" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="mid-side-processing">Mid/side processing</td><td>Stereo representation as sum (mid) and difference (side). In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://en.wikipedia.org/wiki/Joint_encoding#M/S_stereo_coding" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="room-impulse-response-rir">Room impulse response (RIR)</td><td>Acoustic response from source impulse to receiver. In pvx multichannel workflows this directly influences localization cues, interchannel coherence, and translation to speaker or headphone playback.</td><td><a href="https://en.wikipedia.org/wiki/Impulse_response" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="vbap">VBAP</td><td>Vector-base amplitude panning for loudspeaker arrays. VBAP is widely used for loudspeaker panning with controllable phantom-image placement.</td><td><a href="https://scholar.google.com/scholar?q=VBAP+vector+base+amplitude+panning" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table>
<h2 id="analysis-and-qa">Analysis and QA</h2><table><thead><tr><th>Term</th><th>Description</th><th>External link</th></tr></thead><tbody><tr><td id="bayesian-optimization">Bayesian optimization</td><td>Global optimization of expensive objective functions. It is useful when parameter spaces are expensive to evaluate and objective surfaces are noisy.</td><td><a href="https://en.wikipedia.org/wiki/Bayesian_optimization" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="beat-tracking">Beat tracking</td><td>Estimating temporal pulse positions from audio. In pvx analysis and automation tools this determines feature reliability and how confidently metrics can drive downstream decisions.</td><td><a href="https://en.wikipedia.org/wiki/Beat_tracking" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="chord-estimation">Chord estimation</td><td>Inferring harmonic labels from tonal features. In pvx analysis and automation tools this determines feature reliability and how confidently metrics can drive downstream decisions.</td><td><a href="https://scholar.google.com/scholar?q=automatic+chord+estimation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="onset-detection">Onset detection</td><td>Detection of transient musical events. In pvx analysis and automation tools this determines feature reliability and how confidently metrics can drive downstream decisions.</td><td><a href="https://en.wikipedia.org/wiki/Onset_(music)" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="pesq">PESQ</td><td>Perceptual Evaluation of Speech Quality metric. PESQ is speech-focused and should be interpreted alongside task context and listening tests.</td><td><a href="https://en.wikipedia.org/wiki/Perceptual_Evaluation_of_Speech_Quality" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="stoi">STOI</td><td>Short-Time Objective Intelligibility measure. STOI is an intelligibility-oriented metric and does not fully capture timbral preference.</td><td><a href="https://scholar.google.com/scholar?q=STOI+speech+intelligibility" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="structure-segmentation">Structure segmentation</td><td>Dividing music into sections like verse/chorus. In pvx analysis and automation tools this determines feature reliability and how confidently metrics can drive downstream decisions.</td><td><a href="https://scholar.google.com/scholar?q=music+structure+segmentation" target="_blank" rel="noopener">Reference</a></td></tr><tr><td id="visqol">ViSQOL</td><td>Virtual Speech Quality Objective Listener metric family. ViSQOL provides perceptual similarity estimates and is often used with complementary quality metrics.</td><td><a href="https://scholar.google.com/scholar?q=ViSQOL" target="_blank" rel="noopener">Reference</a></td></tr></tbody></table></main>
  <footer class="site-footer">
    <div class="wrap">
      Generated by <code>scripts_generate_html_docs.py</code> from commit <code>b4bed85</code>
      (commit date: 2026-02-19T13:53:32-05:00).
    </div>
  </footer>
</body>
</html>
