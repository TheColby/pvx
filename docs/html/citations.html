<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>pvx Citation Quality</title>
  <link rel="stylesheet" href="style.css" />
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
  <header class="site-header">
    <div class="wrap">
      <h1>pvx Citation Quality</h1>
      <nav><a href="index.html">Home</a> | <a href="papers.html">Research papers</a> | <a href="glossary.html">Glossary</a></nav>
    </div>
  </header>
  <main class="wrap"><div class="card"><h2>Acronym primer</h2><ul><li>application programming interface (API)</li><li>command-line interface (CLI)</li><li>path environment variable (PATH)</li><li>digital signal processing (DSP)</li><li>short-time Fourier transform (STFT)</li><li>inverse short-time Fourier transform (ISTFT)</li><li>fast Fourier transform (FFT)</li><li>discrete Fourier transform (DFT)</li><li>central processing unit (CPU)</li><li>graphics processing unit (GPU)</li><li>Compute Unified Device Architecture (CUDA)</li><li>comma-separated values (CSV)</li><li>JavaScript Object Notation (JSON)</li><li>HyperText Markup Language (HTML)</li><li>Portable Document Format (PDF)</li><li>continuous integration (CI)</li><li>fundamental frequency (F0)</li><li>waveform similarity overlap-add (WSOLA)</li><li>input/output (I/O)</li><li>root-mean-square (RMS)</li><li>loudness units relative to full scale (LUFS)</li><li>signal-to-noise ratio (SNR)</li></ul></div><div class="card"><p>Citation quality report and BibTeX export.</p><p><a href="../references.bib"><code>docs/references.bib</code></a></p></div><h2>Link-Type Summary</h2><table><thead><tr><th>Link type</th><th>Count</th></tr></thead><tbody><tr><td><code>arxiv</code></td><td>7</td></tr><tr><td><code>doi</code></td><td>33</td></tr><tr><td><code>publisher_or_standard</code></td><td>8</td></tr><tr><td><code>scholar</code></td><td>89</td></tr><tr><td><code>web</code></td><td>6</td></tr></tbody></table><h2>Scholar-Link Entries (upgrade candidates)</h2><table><thead><tr><th>Year</th><th>Authors</th><th>Title</th><th>URL</th></tr></thead><tbody><tr><td>1976</td><td>M. R. Portnoff</td><td>Implementation of the Digital Phase Vocoder Using the Fast Fourier Transform</td><td><a href="https://scholar.google.com/scholar?q=Implementation+of+the+Digital+Phase+Vocoder+Using+the+Fast+Fourier+Transform" target="_blank" rel="noopener">link</a></td></tr><tr><td>1980</td><td>M. R. Portnoff</td><td>Time-Scale Modification of Speech Based on Short-Time Fourier Analysis</td><td><a href="https://scholar.google.com/scholar?q=Time-Scale+Modification+of+Speech+Based+on+Short-Time+Fourier+Analysis" target="_blank" rel="noopener">link</a></td></tr><tr><td>1986</td><td>R. J. McAulay; T. F. Quatieri</td><td>Speech Analysis/Synthesis Based on a Sinusoidal Representation</td><td><a href="https://scholar.google.com/scholar?q=Speech+Analysis%2FSynthesis+Based+on+a+Sinusoidal+Representation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2002</td><td>C. Duxbury; M. Davies; M. Sandler</td><td>Improved Time-Scaling of Musical Audio Using Phase Locking at Transients</td><td><a href="https://scholar.google.com/scholar?q=Improved+Time-Scaling+of+Musical+Audio+Using+Phase+Locking+at+Transients" target="_blank" rel="noopener">link</a></td></tr><tr><td>2000</td><td>J. Bonada</td><td>Automatic Technique in Frequency Domain for Near-Lossless Time-Scale Modification of Audio</td><td><a href="https://scholar.google.com/scholar?q=Automatic+Technique+in+Frequency+Domain+for+Near-Lossless+Time-Scale+Modification+of+Audio" target="_blank" rel="noopener">link</a></td></tr><tr><td>1985</td><td>N. Roucos; A. Wilgus</td><td>High Quality Time-Scale Modification for Speech</td><td><a href="https://scholar.google.com/scholar?q=High+Quality+Time-Scale+Modification+for+Speech" target="_blank" rel="noopener">link</a></td></tr><tr><td>1993</td><td>W. Verhelst; M. Roelands</td><td>An Overlap-Add Technique Based on Waveform Similarity (WSOLA) for High Quality Time-Scale Modification of Speech</td><td><a href="https://scholar.google.com/scholar?q=WSOLA+overlap-add+technique+waveform+similarity" target="_blank" rel="noopener">link</a></td></tr><tr><td>2002</td><td>S. Arfib; D. Keiler; U. Zölzer</td><td>DAFX: Digital Audio Effects (chapter references on pitch/time processing)</td><td><a href="https://scholar.google.com/scholar?q=DAFX+Digital+Audio+Effects+pitch+shifting+chapter" target="_blank" rel="noopener">link</a></td></tr><tr><td>1967</td><td>A. M. Noll</td><td>Cepstrum Pitch Determination</td><td><a href="https://scholar.google.com/scholar?q=Cepstrum+Pitch+Determination" target="_blank" rel="noopener">link</a></td></tr><tr><td>1976</td><td>L. R. Rabiner; M. J. Cheng; A. E. Rosenberg; C. A. McGonegal</td><td>A Comparative Performance Study of Several Pitch Detection Algorithms</td><td><a href="https://scholar.google.com/scholar?q=A+Comparative+Performance+Study+of+Several+Pitch+Detection+Algorithms" target="_blank" rel="noopener">link</a></td></tr><tr><td>1995</td><td>D. Talkin</td><td>A Robust Algorithm for Pitch Tracking (RAPT)</td><td><a href="https://scholar.google.com/scholar?q=A+Robust+Algorithm+for+Pitch+Tracking+RAPT" target="_blank" rel="noopener">link</a></td></tr><tr><td>1993</td><td>P. Boersma</td><td>Accurate Short-Term Analysis of the Fundamental Frequency and the Harmonics-to-Noise Ratio of a Sampled Sound</td><td><a href="https://scholar.google.com/scholar?q=Accurate+Short-Term+Analysis+of+the+Fundamental+Frequency+and+the+Harmonics-to-Noise+Ratio" target="_blank" rel="noopener">link</a></td></tr><tr><td>2010</td><td>C. Schörkhuber; A. Klapuri</td><td>Constant-Q Transform Toolbox for Music Processing</td><td><a href="https://scholar.google.com/scholar?q=Constant-Q+Transform+Toolbox+for+Music+Processing" target="_blank" rel="noopener">link</a></td></tr><tr><td>2002</td><td>P. Flandrin; F. Auger; E. Chassande-Mottin</td><td>Time-Frequency Reassignment: From Principles to Algorithms</td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency+Reassignment%3A+From+Principles+to+Algorithms" target="_blank" rel="noopener">link</a></td></tr><tr><td>1991</td><td>S. Mann; S. Haykin</td><td>The Chirplet Transform: Physical Considerations</td><td><a href="https://scholar.google.com/scholar?q=The+Chirplet+Transform%3A+Physical+Considerations" target="_blank" rel="noopener">link</a></td></tr><tr><td>2007</td><td>T. Virtanen</td><td>Monaural Sound Source Separation by Nonnegative Matrix Factorization with Temporal Continuity and Sparseness Criteria</td><td><a href="https://scholar.google.com/scholar?q=Monaural+sound+source+separation+by+nonnegative+matrix+factorization+with+temporal+continuity+and+sparseness+criteria" target="_blank" rel="noopener">link</a></td></tr><tr><td>1949</td><td>N. Wiener</td><td>Extrapolation, Interpolation, and Smoothing of Stationary Time Series</td><td><a href="https://scholar.google.com/scholar?q=Extrapolation+Interpolation+and+Smoothing+of+Stationary+Time+Series+Wiener" target="_blank" rel="noopener">link</a></td></tr><tr><td>1996</td><td>P. Scalart; J. V. Filho</td><td>Speech Enhancement Based on a Priori Signal to Noise Estimation</td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement+Based+on+a+Priori+Signal+to+Noise+Estimation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>Y. Yoshioka; T. Nakatani</td><td>Generalization of Multi-Channel Linear Prediction Methods for Blind MIMO Impulse Response Shortening</td><td><a href="https://scholar.google.com/scholar?q=Generalization+of+Multi-Channel+Linear+Prediction+Methods+for+Blind+MIMO+Impulse+Response+Shortening" target="_blank" rel="noopener">link</a></td></tr><tr><td>1997</td><td>S. Pulkki</td><td>Virtual Sound Source Positioning Using Vector Base Amplitude Panning</td><td><a href="https://scholar.google.com/scholar?q=Virtual+Sound+Source+Positioning+Using+Vector+Base+Amplitude+Panning" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>M. H. C. de Gesmundo et al.</td><td>ViSQOL v3: An Open Source Production Ready Objective Speech and Audio Metric</td><td><a href="https://scholar.google.com/scholar?q=ViSQOL+v3+objective+speech+and+audio+metric" target="_blank" rel="noopener">link</a></td></tr><tr><td>1989</td><td>R. Bristow-Johnson; M. Bogdanowicz</td><td>Phase Vocoder Done Right</td><td><a href="https://scholar.google.com/scholar?q=Phase+Vocoder+Done+Right" target="_blank" rel="noopener">link</a></td></tr><tr><td>1998</td><td>S. Disch</td><td>A New Phase Vocoder Technique for Time-Scale Modification of Audio Signals</td><td><a href="https://scholar.google.com/scholar?q=A+New+Phase+Vocoder+Technique+for+Time-Scale+Modification+of+Audio+Signals" target="_blank" rel="noopener">link</a></td></tr><tr><td>1995</td><td>M. Puckette</td><td>Phase-Locked Vocoder</td><td><a href="https://scholar.google.com/scholar?q=Phase-Locked+Vocoder" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>B. Zavalishin</td><td>The Art of VA Filter Design (sections on phase and spectral processing)</td><td><a href="https://scholar.google.com/scholar?q=The+Art+of+VA+Filter+Design+%28sections+on+phase+and+spectral+processing%29" target="_blank" rel="noopener">link</a></td></tr><tr><td>2009</td><td>N. Moreau</td><td>Toolbox for Time-Scale Modification and Pitch-Shifting of Audio Signals</td><td><a href="https://scholar.google.com/scholar?q=Toolbox+for+Time-Scale+Modification+and+Pitch-Shifting+of+Audio+Signals" target="_blank" rel="noopener">link</a></td></tr><tr><td>2013</td><td>M. Dolson</td><td>History of the Phase Vocoder</td><td><a href="https://scholar.google.com/scholar?q=History+of+the+Phase+Vocoder" target="_blank" rel="noopener">link</a></td></tr><tr><td>2010</td><td>D. S. Hamon; A. Lazarides</td><td>Improved WSOLA for Real-Time Time-Scale Modification</td><td><a href="https://scholar.google.com/scholar?q=Improved+WSOLA+for+Real-Time+Time-Scale+Modification" target="_blank" rel="noopener">link</a></td></tr><tr><td>2015</td><td>M. Riess; A. R. Chhetri</td><td>Transient Preservation in Time-Scale Modification</td><td><a href="https://scholar.google.com/scholar?q=Transient+Preservation+in+Time-Scale+Modification" target="_blank" rel="noopener">link</a></td></tr><tr><td>2008</td><td>J. Bonada</td><td>Wide-Band Harmonic Sinusoidal Modeling for Time-Scale and Pitch-Scale Modification</td><td><a href="https://scholar.google.com/scholar?q=Wide-Band+Harmonic+Sinusoidal+Modeling+for+Time-Scale+and+Pitch-Scale+Modification" target="_blank" rel="noopener">link</a></td></tr><tr><td>2004</td><td>A. de Cheveigne</td><td>Pitch and Time Manipulation of Speech</td><td><a href="https://scholar.google.com/scholar?q=Pitch+and+Time+Manipulation+of+Speech" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>M. Le Roux; E. Vincent</td><td>Consistent Wiener Filtering for Audio Source Separation and Time-Frequency Processing</td><td><a href="https://scholar.google.com/scholar?q=Consistent+Wiener+Filtering+for+Audio+Source+Separation+and+Time-Frequency+Processing" target="_blank" rel="noopener">link</a></td></tr><tr><td>2003</td><td>J. Laroche</td><td>About this Phasiness Business</td><td><a href="https://scholar.google.com/scholar?q=About+this+Phasiness+Business" target="_blank" rel="noopener">link</a></td></tr><tr><td>2014</td><td>J. Driedger; T. Pratzlich; M. Muller</td><td>Let It Bee - Towards NMF-Inspired Audio Mosaicing</td><td><a href="https://scholar.google.com/scholar?q=Let+It+Bee+-+Towards+NMF-Inspired+Audio+Mosaicing" target="_blank" rel="noopener">link</a></td></tr><tr><td>2010</td><td>A. Roebel</td><td>A Shape-Invariant Phase Vocoder for Speech Transformation</td><td><a href="https://scholar.google.com/scholar?q=A+Shape-Invariant+Phase+Vocoder+for+Speech+Transformation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2001</td><td>H. Kawahara; A. de Cheveigne</td><td>STRAIGHT, Exploitation of the Other Aspects of Vocal Source Information</td><td><a href="https://scholar.google.com/scholar?q=STRAIGHT%2C+Exploitation+of+the+Other+Aspects+of+Vocal+Source+Information" target="_blank" rel="noopener">link</a></td></tr><tr><td>2006</td><td>A. Klapuri</td><td>Multiple Fundamental Frequency Estimation by Harmonicity and Spectral Smoothness</td><td><a href="https://scholar.google.com/scholar?q=Multiple+Fundamental+Frequency+Estimation+by+Harmonicity+and+Spectral+Smoothness" target="_blank" rel="noopener">link</a></td></tr><tr><td>2005</td><td>M. McLeod; G. Wyvill</td><td>A Smarter Way to Find Pitch</td><td><a href="https://scholar.google.com/scholar?q=A+Smarter+Way+to+Find+Pitch" target="_blank" rel="noopener">link</a></td></tr><tr><td>1999</td><td>S. Ahmadi; H. Spanias</td><td>Cepstrum-Based Pitch Detection Using FFT</td><td><a href="https://scholar.google.com/scholar?q=Cepstrum-Based+Pitch+Detection+Using+FFT" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>S. Bock; M. Korzeniowski</td><td>piano_transcription - F0 and onset tracking</td><td><a href="https://scholar.google.com/scholar?q=piano_transcription+-+F0+and+onset+tracking" target="_blank" rel="noopener">link</a></td></tr><tr><td>2015</td><td>B. W. Schuller et al.</td><td>Paralinguistics and robust pitch tracking methods</td><td><a href="https://scholar.google.com/scholar?q=Paralinguistics+and+robust+pitch+tracking+methods" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>K. Dressler</td><td>Sinusoidal Extraction using Frequency-Domain Matching Pursuit</td><td><a href="https://scholar.google.com/scholar?q=Sinusoidal+Extraction+using+Frequency-Domain+Matching+Pursuit" target="_blank" rel="noopener">link</a></td></tr><tr><td>2000</td><td>S. Kum; C. L. Nikias</td><td>Robust F0 Estimation in Noise</td><td><a href="https://scholar.google.com/scholar?q=Robust+F0+Estimation+in+Noise" target="_blank" rel="noopener">link</a></td></tr><tr><td>2001</td><td>K. Grochenig</td><td>Foundations of Time-Frequency Analysis</td><td><a href="https://scholar.google.com/scholar?q=Foundations+of+Time-Frequency+Analysis" target="_blank" rel="noopener">link</a></td></tr><tr><td>1998</td><td>P. Flandrin</td><td>Time-Frequency/Time-Scale Analysis</td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency%2FTime-Scale+Analysis" target="_blank" rel="noopener">link</a></td></tr><tr><td>1995</td><td>D. L. Donoho</td><td>De-Noising by Soft-Thresholding</td><td><a href="https://scholar.google.com/scholar?q=De-Noising+by+Soft-Thresholding" target="_blank" rel="noopener">link</a></td></tr><tr><td>1993</td><td>S. Mallat; Z. Zhang</td><td>Matching Pursuits with Time-Frequency Dictionaries</td><td><a href="https://scholar.google.com/scholar?q=Matching+Pursuits+with+Time-Frequency+Dictionaries" target="_blank" rel="noopener">link</a></td></tr><tr><td>1989</td><td>L. Cohen</td><td>Time-Frequency Distributions - A Review</td><td><a href="https://scholar.google.com/scholar?q=Time-Frequency+Distributions+-+A+Review" target="_blank" rel="noopener">link</a></td></tr><tr><td>2010</td><td>A. V. Oppenheim; R. W. Schafer</td><td>Discrete-Time Signal Processing (STFT and filter-bank chapters)</td><td><a href="https://scholar.google.com/scholar?q=Discrete-Time+Signal+Processing+%28STFT+and+filter-bank+chapters%29" target="_blank" rel="noopener">link</a></td></tr><tr><td>2006</td><td>A. C. Gilbert; M. J. Strauss</td><td>Approximation of signals in sparse Fourier dictionaries</td><td><a href="https://scholar.google.com/scholar?q=Approximation+of+signals+in+sparse+Fourier+dictionaries" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>M. Doring; M. M. Kokuer</td><td>Practical NSGT audio applications</td><td><a href="https://scholar.google.com/scholar?q=Practical+NSGT+audio+applications" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>S. Essid; G. Richard</td><td>Musical signal analysis with reassignment methods</td><td><a href="https://scholar.google.com/scholar?q=Musical+signal+analysis+with+reassignment+methods" target="_blank" rel="noopener">link</a></td></tr><tr><td>2007</td><td>P. Smaragdis</td><td>Convolutive Speech Bases and Their Application to Supervised Speech Separation</td><td><a href="https://scholar.google.com/scholar?q=Convolutive+Speech+Bases+and+Their+Application+to+Supervised+Speech+Separation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2009</td><td>C. Fevotte; N. Bertin; J.-L. Durrieu</td><td>Nonnegative Matrix Factorization with the Itakura-Saito Divergence</td><td><a href="https://scholar.google.com/scholar?q=Nonnegative+Matrix+Factorization+with+the+Itakura-Saito+Divergence" target="_blank" rel="noopener">link</a></td></tr><tr><td>2000</td><td>A. Hyvarinen; E. Oja</td><td>Independent Component Analysis: Algorithms and Applications</td><td><a href="https://scholar.google.com/scholar?q=Independent+Component+Analysis%3A+Algorithms+and+Applications" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>E. J. Candes; X. Li; Y. Ma; J. Wright</td><td>Robust Principal Component Analysis?</td><td><a href="https://scholar.google.com/scholar?q=Robust+Principal+Component+Analysis%3F" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>N. Ono</td><td>Stable and fast update rules for independent low-rank matrix analysis based on auxiliary function technique</td><td><a href="https://scholar.google.com/scholar?q=Stable+and+fast+update+rules+for+independent+low-rank+matrix+analysis+based+on+auxiliary+function+technique" target="_blank" rel="noopener">link</a></td></tr><tr><td>1995</td><td>A. J. Bell; T. J. Sejnowski</td><td>An Information-Maximization Approach to Blind Separation and Blind Deconvolution</td><td><a href="https://scholar.google.com/scholar?q=An+Information-Maximization+Approach+to+Blind+Separation+and+Blind+Deconvolution" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>J. Le Roux; S. Wisdom; H. Erdogan; J. R. Hershey</td><td>SDR half-baked or well done?</td><td><a href="https://scholar.google.com/scholar?q=SDR+half-baked+or+well+done%3F" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>A. Defossez et al.</td><td>Music Source Separation in the Waveform Domain</td><td><a href="https://scholar.google.com/scholar?q=Music+Source+Separation+in+the+Waveform+Domain" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>N. Takahashi et al.</td><td>MMDenseLSTM for source separation</td><td><a href="https://scholar.google.com/scholar?q=MMDenseLSTM+for+source+separation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>F.-R. Stoter; S. Uhlich; A. Liutkus; Y. Mitsufuji</td><td>Open-Unmix</td><td><a href="https://scholar.google.com/scholar?q=Open-Unmix" target="_blank" rel="noopener">link</a></td></tr><tr><td>2001</td><td>I. Cohen; B. Berdugo</td><td>Speech Enhancement for Non-Stationary Noise Environments</td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement+for+Non-Stationary+Noise+Environments" target="_blank" rel="noopener">link</a></td></tr><tr><td>1979</td><td>S. Boll</td><td>Suppression of Acoustic Noise in Speech Using Spectral Subtraction</td><td><a href="https://scholar.google.com/scholar?q=Suppression+of+Acoustic+Noise+in+Speech+Using+Spectral+Subtraction" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>T. Yoshioka; T. Nakatani</td><td>Generalization of Multi-Channel Linear Prediction Methods for Blind MIMO Impulse Response Shortening</td><td><a href="https://scholar.google.com/scholar?q=Generalization+of+Multi-Channel+Linear+Prediction+Methods+for+Blind+MIMO+Impulse+Response+Shortening" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>N. D. Gaubitch; P. A. Naylor</td><td>Speech Dereverberation</td><td><a href="https://scholar.google.com/scholar?q=Speech+Dereverberation" target="_blank" rel="noopener">link</a></td></tr><tr><td>2016</td><td>K. Kinoshita et al.</td><td>A summary of the REVERB challenge</td><td><a href="https://scholar.google.com/scholar?q=A+summary+of+the+REVERB+challenge" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>N. W. D. Evans et al.</td><td>The voicehome and CHiME challenges</td><td><a href="https://scholar.google.com/scholar?q=The+voicehome+and+CHiME+challenges" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>J.-M. Valin</td><td>A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement</td><td><a href="https://scholar.google.com/scholar?q=A+Hybrid+DSP%2FDeep+Learning+Approach+to+Real-Time+Full-Band+Speech+Enhancement" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>A. Pandey; D. Wang</td><td>A New Framework for CNN-Based Speech Enhancement in the Time Domain</td><td><a href="https://scholar.google.com/scholar?q=A+New+Framework+for+CNN-Based+Speech+Enhancement+in+the+Time+Domain" target="_blank" rel="noopener">link</a></td></tr><tr><td>2001</td><td>A. Rix et al.</td><td>Perceptual Evaluation of Speech Quality (PESQ)</td><td><a href="https://scholar.google.com/scholar?q=Perceptual+Evaluation+of+Speech+Quality+%28PESQ%29" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>C. Taal et al.</td><td>An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech</td><td><a href="https://scholar.google.com/scholar?q=An+Algorithm+for+Intelligibility+Prediction+of+Time-Frequency+Weighted+Noisy+Speech" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>A. Hines et al.</td><td>VISQOL: An Objective Speech Quality Model</td><td><a href="https://scholar.google.com/scholar?q=VISQOL%3A+An+Objective+Speech+Quality+Model" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>K. K. Paliwal</td><td>Importance of phase in speech enhancement</td><td><a href="https://scholar.google.com/scholar?q=Importance+of+phase+in+speech+enhancement" target="_blank" rel="noopener">link</a></td></tr><tr><td>2013</td><td>P. C. Loizou</td><td>Speech Enhancement: Theory and Practice</td><td><a href="https://scholar.google.com/scholar?q=Speech+Enhancement%3A+Theory+and+Practice" target="_blank" rel="noopener">link</a></td></tr><tr><td>2007</td><td>T. Lund</td><td>Loudness and True-Peak in Digital Audio</td><td><a href="https://scholar.google.com/scholar?q=Loudness+and+True-Peak+in+Digital+Audio" target="_blank" rel="noopener">link</a></td></tr><tr><td>2020</td><td>S. Stables et al.</td><td>A Study of Loudness Normalization in Streaming Services</td><td><a href="https://scholar.google.com/scholar?q=A+Study+of+Loudness+Normalization+in+Streaming+Services" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>M. Fenton</td><td>Practical Dynamics Processing for Modern Music Production</td><td><a href="https://scholar.google.com/scholar?q=Practical+Dynamics+Processing+for+Modern+Music+Production" target="_blank" rel="noopener">link</a></td></tr><tr><td>2011</td><td>J. Reiss</td><td>Under the Hood of a Dynamic Range Compressor</td><td><a href="https://scholar.google.com/scholar?q=Under+the+Hood+of+a+Dynamic+Range+Compressor" target="_blank" rel="noopener">link</a></td></tr><tr><td>2012</td><td>D. Giannoulis; M. Massberg; J. Reiss</td><td>Digital Dynamic Range Compressor Design</td><td><a href="https://scholar.google.com/scholar?q=Digital+Dynamic+Range+Compressor+Design" target="_blank" rel="noopener">link</a></td></tr><tr><td>2015</td><td>M. Ballou</td><td>Handbook for Sound Engineers (Loudness and Dynamics chapters)</td><td><a href="https://scholar.google.com/scholar?q=Handbook+for+Sound+Engineers+%28Loudness+and+Dynamics+chapters%29" target="_blank" rel="noopener">link</a></td></tr><tr><td>2017</td><td>A. Gibiansky et al.</td><td>Deep Voice 2: Multi-Speaker Neural Text-to-Speech</td><td><a href="https://scholar.google.com/scholar?q=Deep+Voice+2%3A+Multi-Speaker+Neural+Text-to-Speech" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>N. Kalchbrenner et al.</td><td>Efficient Neural Audio Synthesis</td><td><a href="https://scholar.google.com/scholar?q=Efficient+Neural+Audio+Synthesis" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>R. Prenger et al.</td><td>WaveGlow: A Flow-based Generative Network for Speech Synthesis</td><td><a href="https://scholar.google.com/scholar?q=WaveGlow%3A+A+Flow-based+Generative+Network+for+Speech+Synthesis" target="_blank" rel="noopener">link</a></td></tr><tr><td>2019</td><td>K. Kumar et al.</td><td>MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis</td><td><a href="https://scholar.google.com/scholar?q=MelGAN%3A+Generative+Adversarial+Networks+for+Conditional+Waveform+Synthesis" target="_blank" rel="noopener">link</a></td></tr><tr><td>2020</td><td>J. Kong et al.</td><td>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</td><td><a href="https://scholar.google.com/scholar?q=HiFi-GAN%3A+Generative+Adversarial+Networks+for+Efficient+and+High+Fidelity+Speech+Synthesis" target="_blank" rel="noopener">link</a></td></tr><tr><td>2017</td><td>Y. Wang et al.</td><td>Tacotron: Towards End-to-End Speech Synthesis</td><td><a href="https://scholar.google.com/scholar?q=Tacotron%3A+Towards+End-to-End+Speech+Synthesis" target="_blank" rel="noopener">link</a></td></tr><tr><td>2021</td><td>S. Wisdom et al.</td><td>Differentiable Consistency Constraints for Improved Deep Speech Enhancement</td><td><a href="https://scholar.google.com/scholar?q=Differentiable+Consistency+Constraints+for+Improved+Deep+Speech+Enhancement" target="_blank" rel="noopener">link</a></td></tr><tr><td>2018</td><td>C. Donahue; J. McAuley; M. Puckette</td><td>Adversarial Audio Synthesis</td><td><a href="https://scholar.google.com/scholar?q=Adversarial+Audio+Synthesis" target="_blank" rel="noopener">link</a></td></tr></tbody></table></main>
  <footer class="site-footer">
    <div class="wrap">
      Generated by <code>scripts_generate_html_docs.py</code> from commit <code>b4bed85</code>
      (commit date: 2026-02-19T13:53:32-05:00).
    </div>
  </footer>
</body>
</html>
